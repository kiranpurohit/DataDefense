
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
  body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 1100px;
  }

  h1 {
    font-weight:300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  .link2 {
    text-decoration: none;
    display: inline;
    margin-right: 5px;
  }

  .fakelink {
    text-decoration: none;
    /* cursor: pointer; */
  }

  element.style {
    overflow: hidden;
    display: block;
  }
  .pre-white-space {
    white-space: pre;
  }
  .bibref {
    margin-top: 10px;
    margin-left: 10px;
    display: none;
    font-size: 14px;
    font-family: monospace;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>
<script type="text/javascript" src="resources/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <head>
    <link rel="icon" type="image/png" href="resources/ucsd_logo.png">
    <title>A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning</title>
    <meta property='og:title' content='A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning' />
    <meta property="og:description" content="Kiran Purohit, Soumi Das, Sourangshu Bhattacharya, Santu Rana. A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning." />
    <meta property='og:url' content='ecai24_datadefense.html' />
  </head>
  <body>
        <br>
        <center><span style="font-size:40px;font-weight:bold;color:#182B49">A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning</span></center>

        <table align=center width=1000px>
          <tr>
            <td align=center width=180px>
              <center><span style="font-size:20px"><a href="https://kiranpurohit.github.io/" target="_blank">Kiran Purohit</a><sup>1</sup></span></center></td>
            <td align=center width=180px>
              <center><span style="font-size:20px"><a href="https://soumidas.github.io/" target="_blank">Soumi Das</a><sup>1</sup></span></center></td>
            <td align=center width=180px>
              <center><span style="font-size:20px"><a href="https://cse.iitkgp.ac.in/~sourangshu/" target="_blank">Sourangshu Bhattacharya</a><sup>1</sup></span></center></td>
            <td align=center width=180px>
              <center><span style="font-size:20px"><a href="https://experts.deakin.edu.au/2644-santu-rana/about" target="_blank">Santu Rana</a><sup>2</sup></span></center></td>
          <tr/>
         </table>
        <!-- <center><span style="font-size:15px;color:#000000">&#8224: Equal Contribution</span></center> -->

        <table align=center width=800px>
          <tr>
            <td align=center width=150px><center><sup>1 </sup><span style="font-size:18px">IIT Kharagpur</span></center></td>
            <td align=center width=150px><center><sup>2 </sup><span style="font-size:18px">Deakin University, Australia</span></center></td> 
            <!-- <td align=center width=150px><center><sup>3 </sup><span style="font-size:18px">IIT Kharagpur</span></center></td> --> 
          <tr/>
        </table> 
        <table align=center width=400px>
          <tr>
            <td align=center width=150px>
              <center><span style="font-size:24px"><a href="https://www.ecai2024.eu/" target="_blank">ECAI 2024</a></span></center></td>
              <!-- <center><span style="font-size:24px"><a href="https://sites.google.com/view/distshift2021/home" target="_blank">NeurIPS DistShift Workshop 2021</a></span></center></td> -->
          <tr/>
        </table>
        <table align=center width=200px>
            <tr><td width=200px>
              <center><a href="required/ecai24_datadefense.png"><img src = "required/ecai24_datadefense.png" width="1000" height="330"></img></a><br></center>
            </td></tr>
        </table>

        <center id="abstract"><h1>Abstract</h1></center>
        Federated Learning systems are increasingly subjected to a multitude of model poisoning attacks from clients. Among these, edge-case attacks that target a small fraction of the input space are nearly impossible to detect using existing defenses, leading to a high attack success rate. We propose an effective defense using an external defense dataset, which provides information about the attack target. The defense dataset contains a mix of poisoned and clean examples, with only a few known to be clean. The proposed method, DataDefense, uses this dataset to learn a poisoned data detector model which marks each example in the defense dataset as poisoned or clean. It also learns a client importance model that estimates the probability of a client update being malicious. The global model is then updated as a weighted average of the client models' updates. The poisoned data detector and the client importance model parameters are updated using an alternating minimization strategy over the Federated Learning rounds. Extensive experiments on standard attack scenarios demonstrate that DataDefense can defend against model poisoning attacks where other state-of-the-art defenses fail. In particular, DataDefense is able to reduce the attack success rate by at least ~ 40% on standard attack setups and by more than 80% on some setups. Furthermore, DataDefense requires very few defense examples (as few as five) to achieve a near-optimal reduction in attack success rate.
        <hr>


        <center id="sourceCode"><h1>Paper & Code</h1></center>


        <table align=center width=900px>
            <tr></tr>
          <tr>
            <td >
        <a href="https://arxiv.org/pdf/2305.02022v2"><img class="paperpreview" src="required/ecai24_datadefense.png" width="250px"/></a>
          </td>
          <td></td>
          <td width=700px > <span style="font-size:20px">
            Kiran Purohit, Soumi Das, Sourangshu Bhattacharya, Santu Rana<br/>
              <a href="https://arxiv.org/abs/2305.02022v2">
                A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning</a> <br/> ECAI, 2024<br/>
            [<a href="https://arxiv.org/pdf/2305.02022v2">PDF</a>]
            [<a href="https://github.com/kiranpurohit/DataDefense_For_Federated_Learning">Code</a>]
            [<a href="">Slides</a>]
            [<a href="">Video</a>]



</span>
        </td>
        </tr>

      </table>

      <br>
      <hr>

      <br/>

    <br><br>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
</body>
</html>
